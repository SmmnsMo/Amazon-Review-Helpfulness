{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (13,15,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv('Updated_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating count vectorizer\n",
    "def make_xy(reviews, column, vectorizer=None):  \n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(reviews[column])\n",
    "    y = reviews['Helpful_review']\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>style</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>...</th>\n",
       "      <th>top_1_pct</th>\n",
       "      <th>review_length</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>year</th>\n",
       "      <th>buckets</th>\n",
       "      <th>review_length_buckets</th>\n",
       "      <th>summary_length_buckets</th>\n",
       "      <th>line_breaks</th>\n",
       "      <th>lemmatized_summaries</th>\n",
       "      <th>lemmatized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Spellbound - I just could not put the book down.</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>A1ME71SSJULX11</td>\n",
       "      <td>Vuyokazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spellbound</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0-50</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Spellbound</td>\n",
       "      <td>Spellbound - I just could not put the book down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Before the written word, stories were passed o...</td>\n",
       "      <td>2015-05-14</td>\n",
       "      <td>A24VCDADYAIHAM</td>\n",
       "      <td>Gridley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telling Tales as of Old</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>251-500</td>\n",
       "      <td>0-5</td>\n",
       "      <td>6</td>\n",
       "      <td>Telling Tales a of Old</td>\n",
       "      <td>Before the write word, story be pass on orally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enjoyed book, written very well</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>A1WR0R3LZVUEU3</td>\n",
       "      <td>Addie Woods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy the book</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0-50</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy the book</td>\n",
       "      <td>Enjoyed book, write very well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was a good story of the Black leagues. I ...</td>\n",
       "      <td>2011-12-25</td>\n",
       "      <td>A6IKXKZMTKGSC</td>\n",
       "      <td>shoecanary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More than facts, a good story read!</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>51-100</td>\n",
       "      <td>6-10</td>\n",
       "      <td>0</td>\n",
       "      <td>More than facts, a good story read!</td>\n",
       "      <td>This be a good story of the Black leagues. I b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>5.0</td>\n",
       "      <td>okay</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>A1QH9MVF3HPZIP</td>\n",
       "      <td>Bicentennial Union High District #76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0-50</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall                                         reviewText  \\\n",
       "0  0143026860      5.0   Spellbound - I just could not put the book down.   \n",
       "1  0143026860      3.0  Before the written word, stories were passed o...   \n",
       "2  0143026860      5.0                    Enjoyed book, written very well   \n",
       "3  0143026860      5.0  This was a good story of the Black leagues. I ...   \n",
       "4  0143026860      5.0                                               okay   \n",
       "\n",
       "   reviewTime      reviewerID                          reviewerName style  \\\n",
       "0  2017-10-23  A1ME71SSJULX11                              Vuyokazi   NaN   \n",
       "1  2015-05-14  A24VCDADYAIHAM                               Gridley   NaN   \n",
       "2  2017-05-26  A1WR0R3LZVUEU3                           Addie Woods   NaN   \n",
       "3  2011-12-25   A6IKXKZMTKGSC                            shoecanary   NaN   \n",
       "4  2016-09-13  A1QH9MVF3HPZIP  Bicentennial Union High District #76   NaN   \n",
       "\n",
       "                               summary  verified  vote  ... top_1_pct  \\\n",
       "0                           Spellbound      True     0  ...        no   \n",
       "1              Telling Tales as of Old      True     0  ...        no   \n",
       "2                         Buy the book      True     0  ...        no   \n",
       "3  More than facts, a good story read!      True     5  ...        no   \n",
       "4                           Five Stars      True     0  ...        no   \n",
       "\n",
       "  review_length summary_length  year buckets review_length_buckets  \\\n",
       "0             9              1  2017       0                  0-50   \n",
       "1           318              5  2015       0               251-500   \n",
       "2             5              3  2017       0                  0-50   \n",
       "3            68              7  2011       0                51-100   \n",
       "4             1              2  2016       0                  0-50   \n",
       "\n",
       "   summary_length_buckets line_breaks                 lemmatized_summaries  \\\n",
       "0                     0-5           0                           Spellbound   \n",
       "1                     0-5           6               Telling Tales a of Old   \n",
       "2                     0-5           0                         Buy the book   \n",
       "3                    6-10           0  More than facts, a good story read!   \n",
       "4                     0-5           0                           Five Stars   \n",
       "\n",
       "                                  lemmatized_reviews  \n",
       "0   Spellbound - I just could not put the book down.  \n",
       "1  Before the write word, story be pass on orally...  \n",
       "2                      Enjoyed book, write very well  \n",
       "3  This be a good story of the Black leagues. I b...  \n",
       "4                                               okay  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['reviewText'] = reviews['reviewText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['lemmatized_reviews'] = reviews['lemmatized_reviews'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_xy(reviews, 'lemmatized_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews.drop('Helpful_review', axis = 1)\n",
    "Y = reviews['Helpful_review'] #Creating X and Y for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_df = reviews[reviews.index.isin(test_index)] \n",
    "#Creating a consistent test set to test same sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_df = reviews[reviews.index.isin(train_index)] \n",
    "#Creating a consistent training set so I can use the same training sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = list(Y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = []\n",
    "for i in range(0, len(reviews)):\n",
    "    if rev_ind[i] not in test_index:\n",
    "        train_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_df = reviews[reviews.index.isin(test_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_df = reviews[reviews.index.isin(train_index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be creating multiple text classifiers to see which type performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_param_grid = {'alpha': [.1,.5,1]}\n",
    "clf_NB_CV_overall = GridSearchCV(clf, clf_param_grid, cv = 5).fit(x[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.633310035609119"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_score = balanced_accuracy_score(y[test_index], clf_NB_CV_overall.predict(x[test_index]))\n",
    "NB_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_roc_score = roc_auc_score(y[test_index], clf_NB_CV_overall.predict_proba(x[test_index])[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5889194087853167"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {'n_estimators': [5,10,15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_CV = GridSearchCV(clf_rf, param_grid_rf, cv = 5).fit(x[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800652531861668"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score = balanced_accuracy_score(y[test_index], clf_rf_CV.predict(x[test_index]))\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SGDC = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'average': False,\n",
       " 'class_weight': None,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.15,\n",
       " 'learning_rate': 'optimal',\n",
       " 'loss': 'hinge',\n",
       " 'max_iter': 1000,\n",
       " 'n_iter_no_change': 5,\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'tol': 0.001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_SGDC.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_SGDC = {'alpha': [.0001, .001, .01, 1], 'loss':['log']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SGDC_CV = GridSearchCV(clf_SGDC, param_grid_SGDC, cv = 5).fit(x[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5501417425773983"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDC_score = balanced_accuracy_score(Y_test, clf_SGDC_CV.predict(x[test_index]))\n",
    "SGDC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LSVC = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': True,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LSVC.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lsvc = {'C': [.01,.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_LSVC_CV = GridSearchCV(clf_LSVC, param_grid_lsvc, cv = 5).fit(x[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6004368739281801"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC_score = balanced_accuracy_score(Y_test, clf_LSVC_CV.predict(x[test_index]))\n",
    "LSVC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'], 'C': [.01,.1,1,10]}\n",
    "clf_log_CV = GridSearchCV(clf_log, param_grid, cv = 5).fit(x[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.574724962249412"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_reg_score = balanced_accuracy_score(y[test_index], clf_log_CV.predict(x[test_index]))\n",
    "Log_reg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sum, Y_sum = make_xy(reviews, 'lemmatized_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_sum_SGDC = {'alpha': [.0001, .001, .01, 1], 'loss' : ['log']}\n",
    "clf_sum_SGDC_CV = GridSearchCV(clf_SGDC, param_grid_sum_SGDC, cv = 5).fit(X_sum[train_index], Y_sum[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sum_SGDC_CV_score = balanced_accuracy_score(Y_sum[test_index], clf_sum_SGDC_CV.predict(X_sum[test_index]))\n",
    "clf_sum_SGDC_CV_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sum_NB = GridSearchCV(clf, clf_param_grid, cv = 5).fit(X_sum[train_index], Y_sum[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5672020230427373"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sum_NB_score = balanced_accuracy_score(Y_sum[test_index], clf_sum_NB.predict(X_sum[test_index]))\n",
    "clf_sum_NB_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_sum = GridSearchCV(clf_rf, param_grid_rf, cv = 5).fit(X_sum[train_index], Y_sum[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5391935020589124"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_sum_score = balanced_accuracy_score(Y_sum[test_index], rf_sum.predict(X_sum[test_index]))\n",
    "rf_sum_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "LSVC_sum = GridSearchCV(clf_LSVC, param_grid_lsvc, cv = 5).fit(X_sum[train_index], Y_sum[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5065244586965831"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC_sum_score = balanced_accuracy_score(Y_sum[test_index], LSVC_sum.predict(X_sum[test_index]))\n",
    "LSVC_sum_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Log_reg_sum = GridSearchCV(clf_log, param_grid, cv=5).fit(X_sum[train_index], Y_sum[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_reg_sum_score = balanced_accuracy_score(Y_sum[test_index], Log_reg_sum.predict(X_sum[test_index]))\n",
    "Log_reg_sum_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding multiple features to the model - lemmatized reviews, lemmatized summaries, year, review length, summary length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "label_enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categories = enc.fit(reviews[['year','summary_length_buckets','review_length_buckets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = reviews['year']\n",
    "summary_buckets = reviews['summary_length_buckets']\n",
    "review_buckets = reviews['review_length_buckets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_years = label_enc.fit_transform(np.array(years))\n",
    "label_encoded_sum_L = label_enc.fit_transform(np.array(summary_buckets))\n",
    "label_encoded_review_L = label_enc.fit_transform(np.array(review_buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_years = label_encoded_years.reshape(len(label_encoded), 1)\n",
    "label_encoded_sum_L = label_encoded_sum_L.reshape(len(label_encoded), 1)\n",
    "label_encoded_review_L = label_encoded_review_L.reshape(len(label_encoded), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_enc_years = enc.fit_transform(label_encoded_years)\n",
    "onehot_enc_sum_L = enc.fit_transform(label_encoded_sum_L)\n",
    "onehot_enc_review_L = enc.fit_transform(label_encoded_review_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_enc_years = onehot_enc_years.tocsc()\n",
    "onehot_enc_sum_L = onehot_enc_sum_L.tocsc()\n",
    "onehot_enc_review_L = onehot_enc_review_L.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = hstack([onehot_enc_years, onehot_enc_sum_L, onehot_enc_review_L, x, X_sum]).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_NB_param_grid = {'alpha': [.1,.5,1]}\n",
    "clf_NB_CV_total = GridSearchCV(clf, clf_param_grid, cv = 5).fit(X_total[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823374878322167"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_total_score = balanced_accuracy_score(y[test_index], clf_NB_CV_total.predict(X_total[test_index]))\n",
    "NB_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_CV_total = GridSearchCV(clf_rf, param_grid_rf, cv = 5).fit(X_total[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5862594819001397"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_total_score = balanced_accuracy_score(y[test_index], clf_rf_CV_total.predict(X_total[test_index]))\n",
    "RF_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SGDC_total = GridSearchCV(clf_SGDC, param_grid_SGDC, cv = 5).fit(X_total[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63275228232648"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_SGDC_total_score = balanced_accuracy_score(y[test_index], clf_SGDC_total.predict(X_total[test_index]))\n",
    "clf_SGDC_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "LSVC_total = GridSearchCV(clf_LSVC, param_grid_lsvc, cv = 5).fit(X_total[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417232427819664"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC_total_score = balanced_accuracy_score(y[test_index], LSVC_total.predict(X_total[test_index]))\n",
    "LSVC_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_log_reg_total = GridSearchCV(clf_log, param_grid, cv = 5).fit(X_total[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639301232863883"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log_reg_total_score = balanced_accuracy_score(y[test_index], clf_log_reg_total.predict(X_total[test_index]))\n",
    "clf_log_reg_total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = ['Naive Bayes', 'Random Forest', 'SGDC', 'LSVC', 'Logistic Regression']\n",
    "Review_Scores = [NB_score, rf_score, SGDC_score, LSVC_score, Log_reg_score]\n",
    "Summary_Scores = [clf_sum_NB_score, rf_sum_score, clf_sum_SGDC_CV_score, LSVC_sum_score, Log_reg_sum_score]\n",
    "Total_Scores = [NB_total_score, RF_total_score, clf_SGDC_total_score, LSVC_total_score, clf_log_reg_total_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_scores = pd.DataFrame(data = [Models, Review_Scores, Summary_Scores, Total_Scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_scores = baseline_scores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Review_Scores</th>\n",
       "      <th>Summary_Scores</th>\n",
       "      <th>Total_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.63331</td>\n",
       "      <td>0.567202</td>\n",
       "      <td>0.682337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.580065</td>\n",
       "      <td>0.539194</td>\n",
       "      <td>0.586259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDC</td>\n",
       "      <td>0.550142</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.632752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSVC</td>\n",
       "      <td>0.600437</td>\n",
       "      <td>0.506524</td>\n",
       "      <td>0.641723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.574725</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.639301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Models Review_Scores Summary_Scores Total_Scores\n",
       "0          Naive Bayes       0.63331       0.567202     0.682337\n",
       "1        Random Forest      0.580065       0.539194     0.586259\n",
       "2                 SGDC      0.550142            0.5     0.632752\n",
       "3                 LSVC      0.600437       0.506524     0.641723\n",
       "4  Logistic Regression      0.574725            0.5     0.639301"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores.rename(columns = {0: 'Models', 1: 'Review_Scores', 2:'Summary_Scores', 3:'Total_Scores'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a Naive Bayes model that uses the categorical data is the best predictor, with a balanced accuracy score of .682."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(reviews['category'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['office_products',\n",
       " 'toys',\n",
       " 'amazon_fashion',\n",
       " 'video_games',\n",
       " 'pet_supplies',\n",
       " 'all_beauty',\n",
       " 'automotive',\n",
       " 'tools',\n",
       " 'movies',\n",
       " 'music',\n",
       " 'grocery',\n",
       " 'kindle',\n",
       " 'software',\n",
       " 'musical_instruments',\n",
       " 'luxury_beauty',\n",
       " 'appliances',\n",
       " 'arts_crafts',\n",
       " 'industrial',\n",
       " 'prime_pantry',\n",
       " 'patio',\n",
       " 'cds_and_vinyl']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CR for categorical reviews\n",
    "overall_true = []\n",
    "overall_pred= []\n",
    "cat_results = []\n",
    "category = []\n",
    "for i in categories:\n",
    "    df_train = training_set_df[training_set_df['category'] == i]\n",
    "    df_test = test_set_df[test_set_df['category'] == i]\n",
    "    \n",
    "    clf_NB_CV = GridSearchCV(clf, clf_param_grid, cv = 5).fit(X_total[df_train.index], y[df_train.index])\n",
    "    score = balanced_accuracy_score(y[df_test.index], clf_NB_CV.predict(X_total[df_test.index]))\n",
    "    \n",
    "    overall_pred.append(clf_NB_CV.predict(X_total[df_test.index]).tolist())\n",
    "    overall_true.append((y[df_test.index]).tolist())\n",
    "    \n",
    "    cat_results.append(score)\n",
    "    category.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_T = []\n",
    "for i in range(0, len(overall_true)):\n",
    "    overall_T = overall_T + overall_true[i]\n",
    "\n",
    "overall_P = []\n",
    "for i in range(0, len(overall_pred)):\n",
    "    overall_P = overall_P + overall_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {'category': category, 'review_results': cat_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6156800651598846"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(overall_T, overall_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75419,  2262],\n",
       "       [12438,  4381]])"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(overall_T, overall_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>0.740399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.732537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>software</td>\n",
       "      <td>0.715068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>appliances</td>\n",
       "      <td>0.711715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video_games</td>\n",
       "      <td>0.666656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>musical_instruments</td>\n",
       "      <td>0.638020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patio</td>\n",
       "      <td>0.555994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>music</td>\n",
       "      <td>0.555365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tools</td>\n",
       "      <td>0.533910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>office_products</td>\n",
       "      <td>0.526142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arts_crafts</td>\n",
       "      <td>0.512957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grocery</td>\n",
       "      <td>0.508793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>luxury_beauty</td>\n",
       "      <td>0.508493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>industrial</td>\n",
       "      <td>0.507948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_supplies</td>\n",
       "      <td>0.507368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kindle</td>\n",
       "      <td>0.501226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toys</td>\n",
       "      <td>0.500397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_beauty</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>prime_pantry</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>automotive</td>\n",
       "      <td>0.499878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon_fashion</td>\n",
       "      <td>0.499873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category  review_results\n",
       "20        cds_and_vinyl        0.740399\n",
       "8                movies        0.732537\n",
       "12             software        0.715068\n",
       "15           appliances        0.711715\n",
       "3           video_games        0.666656\n",
       "13  musical_instruments        0.638020\n",
       "19                patio        0.555994\n",
       "9                 music        0.555365\n",
       "7                 tools        0.533910\n",
       "0       office_products        0.526142\n",
       "16          arts_crafts        0.512957\n",
       "10              grocery        0.508793\n",
       "14        luxury_beauty        0.508493\n",
       "17           industrial        0.507948\n",
       "4          pet_supplies        0.507368\n",
       "11               kindle        0.501226\n",
       "1                  toys        0.500397\n",
       "5            all_beauty        0.500000\n",
       "18         prime_pantry        0.500000\n",
       "6            automotive        0.499878\n",
       "2        amazon_fashion        0.499873"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_predictions = pd.DataFrame(data = cat_dict)\n",
    "categorical_predictions.sort_values(by = 'review_results', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data up by category results in a balanced accuracy score that is significantly worse than a generalized model:\n",
    "\n",
    "Generalized Model = .682\n",
    "<br />\n",
    "Category Specific = .62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sum, y_sum = make_xy(reviews, 'lemmatized_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a training and testing dict for combinations - just in case\n",
    "\n",
    "training_set_dict_x = {}\n",
    "training_set_dict_y = {}\n",
    "test_set_dict_x = {}\n",
    "test_set_dict_y = {}\n",
    "\n",
    "for i in categories:\n",
    "    df_dict_train = training_set_df[training_set_df['category'] == i]\n",
    "    values_train_x = df_dict_train['lemmatized_reviews']\n",
    "    values_train_y = df_dict_train['Helpful_review']\n",
    "    training_set_dict_x[i] = values_train_x\n",
    "    training_set_dict_y[i] = values_train_y\n",
    "    \n",
    "    df_dict_test = test_set_df[test_set_df['category'] == i]\n",
    "    values_test_x = df_dict_test['lemmatized_reviews']\n",
    "    values_test_y = df_dict_test['Helpful_review']\n",
    "    test_set_dict_x[i] = values_test_x\n",
    "    test_set_dict_y[i] = values_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_param_grid = {'alpha': [.1,.5,1]}\n",
    "clf_NB_CV_overall = GridSearchCV(clf, clf_param_grid, cv = 5).fit(x[train_index], y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5468940463690455"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(test_set_dict_y['toys'],clf_NB_CV_overall.predict(x[test_set_dict_x['toys'].index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalized_dict = {}\n",
    "overall_cat_predictions = []\n",
    "\n",
    "for i in categories:\n",
    "    overall_cat_predictions = balanced_accuracy_score(test_set_dict_y[i], clf_NB_CV_overall.predict(x[test_set_dict_x[i].index]))\n",
    "    generalized_dict[i] = overall_cat_predictions\n",
    "    \n",
    "generalized_model_results = pd.DataFrame(data = generalized_dict.values(), index = generalized_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_predictions['generalized_model_score'] = list(generalized_model_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>review_results</th>\n",
       "      <th>generalized_model_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>office_products</td>\n",
       "      <td>0.500469</td>\n",
       "      <td>0.566643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toys</td>\n",
       "      <td>0.501051</td>\n",
       "      <td>0.546894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon_fashion</td>\n",
       "      <td>0.499745</td>\n",
       "      <td>0.506788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video_games</td>\n",
       "      <td>0.628459</td>\n",
       "      <td>0.689218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_supplies</td>\n",
       "      <td>0.500750</td>\n",
       "      <td>0.522021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_beauty</td>\n",
       "      <td>0.499737</td>\n",
       "      <td>0.512211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>automotive</td>\n",
       "      <td>0.499634</td>\n",
       "      <td>0.523605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tools</td>\n",
       "      <td>0.500481</td>\n",
       "      <td>0.529954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.693127</td>\n",
       "      <td>0.712392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>music</td>\n",
       "      <td>0.514036</td>\n",
       "      <td>0.728777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grocery</td>\n",
       "      <td>0.504615</td>\n",
       "      <td>0.515445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kindle</td>\n",
       "      <td>0.500441</td>\n",
       "      <td>0.582091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>software</td>\n",
       "      <td>0.669510</td>\n",
       "      <td>0.696507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>musical_instruments</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>0.621363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>luxury_beauty</td>\n",
       "      <td>0.499667</td>\n",
       "      <td>0.509495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>appliances</td>\n",
       "      <td>0.678189</td>\n",
       "      <td>0.616556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arts_crafts</td>\n",
       "      <td>0.501293</td>\n",
       "      <td>0.519924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>industrial</td>\n",
       "      <td>0.501753</td>\n",
       "      <td>0.546590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>prime_pantry</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.509984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patio</td>\n",
       "      <td>0.501682</td>\n",
       "      <td>0.535518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>0.689610</td>\n",
       "      <td>0.716473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category  review_results  generalized_model_score\n",
       "0       office_products        0.500469                 0.566643\n",
       "1                  toys        0.501051                 0.546894\n",
       "2        amazon_fashion        0.499745                 0.506788\n",
       "3           video_games        0.628459                 0.689218\n",
       "4          pet_supplies        0.500750                 0.522021\n",
       "5            all_beauty        0.499737                 0.512211\n",
       "6            automotive        0.499634                 0.523605\n",
       "7                 tools        0.500481                 0.529954\n",
       "8                movies        0.693127                 0.712392\n",
       "9                 music        0.514036                 0.728777\n",
       "10              grocery        0.504615                 0.515445\n",
       "11               kindle        0.500441                 0.582091\n",
       "12             software        0.669510                 0.696507\n",
       "13  musical_instruments        0.564210                 0.621363\n",
       "14        luxury_beauty        0.499667                 0.509495\n",
       "15           appliances        0.678189                 0.616556\n",
       "16          arts_crafts        0.501293                 0.519924\n",
       "17           industrial        0.501753                 0.546590\n",
       "18         prime_pantry        0.500000                 0.509984\n",
       "19                patio        0.501682                 0.535518\n",
       "20        cds_and_vinyl        0.689610                 0.716473"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in nearly every category that the generalized model performs better than a model that is trained category specific. The only exception was appliances where the category specific model has a balanced accuracy score that is .06 higher than the generalized model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.87      0.93      0.90     77681\n",
      "         yes       0.50      0.34      0.40     16819\n",
      "\n",
      "    accuracy                           0.82     94500\n",
      "   macro avg       0.68      0.63      0.65     94500\n",
      "weighted avg       0.80      0.82      0.81     94500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y[test_index], clf_NB_CV_overall.predict(x[test_index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894962760335283"
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y[test_index], clf_NB_CV_total.predict(X_total[test_index]), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_proba = clf_NB_CV_total.predict_proba(X_total[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_proba = clf_rf_CV_total.predict_proba(X_total[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SGDC_proba = clf_SGDC_total.predict_proba(X_total[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_reg_proba = clf_log_reg_total.predict_proba(X_total[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframes of the predicted probabilities from each model\n",
    "NB = pd.DataFrame(NB_proba)\n",
    "RF = pd.DataFrame(rf_proba)\n",
    "SGDC = pd.DataFrame(SGDC_proba)\n",
    "LogReg = pd.DataFrame(Log_reg_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pred_proba = pd.DataFrame(NB[1])\n",
    "models_pred_proba['RF'] = RF[1]\n",
    "models_pred_proba['SGDC'] = SGDC[1]\n",
    "models_pred_proba['LogReg'] = LogReg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pred_proba = models_pred_proba.rename(columns = {1: 'NB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of thresholds\n",
    "thresh_list = [.01, .025 ,.05, .1, .15, .2, .25, .3, .35, .4, .45, .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function produces probability predictions and compares them against a discrimination threshold\n",
    "def f1_score_thresh(df, model, thresh):\n",
    "    return df[model] > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These series of loops optimizes each model by going through a list of discrimination thresholds \n",
    "#Models using all inputs\n",
    "f1_score_NB_total = []\n",
    "threshold = []\n",
    "for j in thresh_list: #Creating a list of f1 scores for various thresholds\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_pred_proba, 'NB', j)\n",
    "    for i in f1_score_thresh(models_pred_proba, 'NB', j): #Setting each row to yes or no instead of True/False\n",
    "        if f1_score_thresh(models_pred_proba, 'NB', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "    f1_score_NB_total.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.451158954820799"
      ]
     },
     "execution_count": 1347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_NB_total_highest = np.max(f1_score_NB_total)\n",
    "f1_score_NB_total_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_RF = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_pred_proba, 'RF', j)\n",
    "    for i in f1_score_thresh(models_pred_proba, 'RF', j):\n",
    "        if f1_score_thresh(models_pred_proba, 'RF', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "    f1_score_RF.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.651030742023905"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_RF_total_highest = np.max(f1_score_RF)\n",
    "f1_score_RF_total_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_SGDC = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_pred_proba, 'SGDC', j)\n",
    "    for i in f1_score_thresh(models_pred_proba, 'SGDC', j):\n",
    "        if f1_score_thresh(models_pred_proba, 'SGDC', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "    f1_score_SGDC.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5312181187083436"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_SGDC_total_highest = np.max(f1_score_SGDC)\n",
    "f1_score_SGDC_total_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_Log_reg = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_pred_proba, 'LogReg', j)\n",
    "    for i in f1_score_thresh(models_pred_proba, 'LogReg', j):\n",
    "        if f1_score_thresh(models_pred_proba, 'LogReg', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "    f1_score_Log_reg.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5239285759621033"
      ]
     },
     "execution_count": 1350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_Log_reg_total_highest = np.max(f1_score_Log_reg)\n",
    "f1_score_Log_reg_total_highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the random forest model that uses the reviews, summaries and categorical features has the highest f1 score at .65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_reviews_proba = clf_NB_CV_overall.predict_proba(x[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_reviews_proba = clf_rf_CV.predict_proba(x[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDC_reviews_proba = clf_SGDC_CV.predict_proba(x[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_reg_reviews_proba = clf_log_CV.predict_proba(x[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = pd.DataFrame(NB_reviews_proba)\n",
    "RF = pd.DataFrame(RF_reviews_proba)\n",
    "SGDC = pd.DataFrame(SGDC_reviews_proba)\n",
    "LogReg = pd.DataFrame(Log_reg_reviews_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rev_pred_proba = pd.DataFrame(NB[1])\n",
    "models_rev_pred_proba['RF'] = RF[1]\n",
    "models_rev_pred_proba['SGDC'] = SGDC[1]\n",
    "models_rev_pred_proba['LogReg'] = LogReg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rev_pred_proba = models_rev_pred_proba.rename(columns = {1: 'NB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>SGDC</th>\n",
       "      <th>LogReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.099447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.236297</td>\n",
       "      <td>0.111637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231608</td>\n",
       "      <td>0.132971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.211797</td>\n",
       "      <td>0.132946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.154990</td>\n",
       "      <td>0.099848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NB        RF      SGDC    LogReg\n",
       "0  0.016466  0.000000  0.200013  0.099447\n",
       "1  0.601111  0.266667  0.236297  0.111637\n",
       "2  0.171097  0.000000  0.231608  0.132971\n",
       "3  0.011662  0.066667  0.211797  0.132946\n",
       "4  0.010503  0.066667  0.154990  0.099848"
      ]
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_rev_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models using only reviews \n",
    "f1_score_rev_NB = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_rev_pred_proba, 'NB', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_rev_pred_proba, 'NB', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_rev_NB.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6499791878124489"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_NB_rev_max = np.max(f1_score_rev_NB)\n",
    "f1_score_NB_rev_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_rev_RF = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_rev_pred_proba, 'RF', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_rev_pred_proba, 'RF', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_rev_RF.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6684169363483298"
      ]
     },
     "execution_count": 1356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_f1_score_rev_RF = np.max(f1_score_rev_RF)\n",
    "highest_f1_score_rev_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_rev_SGDC = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_rev_pred_proba, 'SGDC', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_rev_pred_proba, 'SGDC', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_rev_SGDC.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5312181187083436"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_rev_SGDC_max = np.max(f1_score_SGDC)\n",
    "f1_score_rev_SGDC_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_rev_Log_reg = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_rev_pred_proba, 'LogReg', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_rev_pred_proba, 'LogReg', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_rev_Log_reg.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5239285759621033"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_rev_Log_reg_max = np.max(f1_score_Log_reg)\n",
    "f1_score_rev_Log_reg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model that only used the reviews as inputs yielded the highest f1 score of .67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_sum_proba = clf_sum_NB.predict_proba(X_sum[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_sum_proba = rf_sum.predict_proba(X_sum[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDC_sum_proba = clf_sum_SGDC_CV.predict_proba(X_sum[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_reg_sum_proba = Log_reg_sum.predict_proba(X_sum[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = pd.DataFrame(NB_sum_proba)\n",
    "RF = pd.DataFrame(RF_sum_proba)\n",
    "SGDC = pd.DataFrame(SGDC_sum_proba)\n",
    "LogReg = pd.DataFrame(Log_reg_sum_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sum_pred_proba = pd.DataFrame(NB[1])\n",
    "models_sum_pred_proba['RF'] = RF[1]\n",
    "models_sum_pred_proba['SGDC'] = SGDC[1]\n",
    "models_sum_pred_proba['LogReg'] = LogReg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sum_pred_proba = models_sum_pred_proba.rename(columns = {1: 'NB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>SGDC</th>\n",
       "      <th>LogReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.041228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.362365</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.287697</td>\n",
       "      <td>0.239621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102848</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.254754</td>\n",
       "      <td>0.240039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066672</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212872</td>\n",
       "      <td>0.246756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.033804</td>\n",
       "      <td>0.068322</td>\n",
       "      <td>0.036753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NB        RF      SGDC    LogReg\n",
       "0  0.002961  0.031522  0.102941  0.041228\n",
       "1  0.362365  0.266667  0.287697  0.239621\n",
       "2  0.102848  0.400000  0.254754  0.240039\n",
       "3  0.066672  0.200000  0.212872  0.246756\n",
       "4  0.002997  0.033804  0.068322  0.036753"
      ]
     },
     "execution_count": 1318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_sum_pred_proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models only using summaries\n",
    "f1_score_sum_NB = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_sum_pred_proba, 'NB', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_sum_pred_proba, 'NB', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_sum_NB.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125988896995122"
      ]
     },
     "execution_count": 1320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_NB_sum = np.max(f1_score_sum_NB)\n",
    "f1_score_NB_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_sum_RF = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_sum_pred_proba, 'RF', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_sum_pred_proba, 'RF', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_sum_RF.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5908855606764365"
      ]
     },
     "execution_count": 1322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_sum_RF = np.max(f1_score_sum_RF)\n",
    "f1_score_sum_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arensimmons/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1_score_sum_SGDC = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_sum_pred_proba, 'SGDC', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_sum_pred_proba, 'SGDC', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_sum_SGDC.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5635194251380714"
      ]
     },
     "execution_count": 1324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_sum_SGDC = np.max(f1_score_sum_SGDC)\n",
    "f1_score_sum_SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_sum_Log_reg = []\n",
    "for j in thresh_list:\n",
    "    k = []\n",
    "    __ = []\n",
    "    f1_score_thresh(models_sum_pred_proba, 'LogReg', j)\n",
    "    for i in range(0, 94500):\n",
    "        if f1_score_thresh(models_sum_pred_proba, 'LogReg', j)[i] == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)\n",
    "        \n",
    "    f1_score_sum_Log_reg.append(f1_score(y[test_index], __, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5658990281698539"
      ]
     },
     "execution_count": 1326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_sum_Log_reg = np.max(f1_score_sum_Log_reg)\n",
    "f1_score_sum_Log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_sum_scores = [f1_score_NB_sum, f1_score_sum_RF, f1_score_sum_SGDC, f1_score_sum_Log_reg]\n",
    "f1_rev_scores = [f1_score_NB_rev, f1_score_rev_RF, f1_score_rev_SGDC, f1_score_rev_Log_reg]\n",
    "f1_total_scores = [f1_score_NB_total, f1_score_RF_total, f1_score_SGDC_total, f1_score_Log_reg_total]\n",
    "f1_scores_models = ['NB', 'RF', 'SGDC', 'Log_Reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Review_Scores': f1_rev_scores, 'Summary_Scores': f1_sum_scores, 'Total_scores': f1_total_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Scores</th>\n",
       "      <th>Summary_Scores</th>\n",
       "      <th>Total_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.649979</td>\n",
       "      <td>0.612599</td>\n",
       "      <td>0.451159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.668417</td>\n",
       "      <td>0.590886</td>\n",
       "      <td>0.651031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDC</th>\n",
       "      <td>0.531218</td>\n",
       "      <td>0.563519</td>\n",
       "      <td>0.531218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log_Reg</th>\n",
       "      <td>0.523929</td>\n",
       "      <td>0.565899</td>\n",
       "      <td>0.523929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Review_Scores  Summary_Scores  Total_scores\n",
       "NB            0.649979        0.612599      0.451159\n",
       "RF            0.668417        0.590886      0.651031\n",
       "SGDC          0.531218        0.563519      0.531218\n",
       "Log_Reg       0.523929        0.565899      0.523929"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores_df = pd.DataFrame(index = f1_scores_models, data = d)\n",
    "f1_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a random forest model that just uses the reviews yields the highest f1 score of .668."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CR for categorical reviews\n",
    "#This loop works the same as the previous loops which optimize the RF model for f1 scores with threshold of 0.3\n",
    "#Difference is that this loop is for an ensemble model trained on specific categories\n",
    "#Also uses a generic model to predict on category specific data\n",
    "overall_true_cat = []\n",
    "overall_pred_cat = []\n",
    "overall_pred_gen = []\n",
    "\n",
    "cat_results = []\n",
    "gen_cat_results = []\n",
    "category = []\n",
    "\n",
    "for i in categories:\n",
    "    df_train = training_set_df[training_set_df['category'] == i]\n",
    "    df_test = test_set_df[test_set_df['category'] == i]\n",
    "    \n",
    "    clf_rf_CV_cat = GridSearchCV(clf_rf, param_grid_rf, cv = 5).fit(x[df_train.index], y[df_train.index])\n",
    "    \n",
    "    proba = pd.DataFrame(clf_rf_CV_cat.predict_proba(x[df_test.index]))[1] > 0.3\n",
    "    proba_gen = pd.DataFrame(clf_rf_CV.predict_proba(x[df_test.index]))[1] > 0.3\n",
    "    \n",
    "    __ = []\n",
    "    __g = []\n",
    "    \n",
    "    for j in proba:\n",
    "        if j == True:\n",
    "            k = 'yes'\n",
    "        else:\n",
    "            k = 'no'\n",
    "        __.append(k)    #List of predicted values of y from category specific model \n",
    "        \n",
    "    for l in proba_gen:\n",
    "        if l == True:\n",
    "            r = 'yes'\n",
    "        else:\n",
    "            r = 'no'\n",
    "        __g.append(r) #List of predicted values of y from generalized model\n",
    "            \n",
    "    score = f1_score(list(y[df_test.index]), __, average = 'macro')\n",
    "    gen_score = f1_score(list(y[df_test.index]), __g, average = 'macro')\n",
    "                         \n",
    "    overall_pred_cat.append(__)\n",
    "    overall_pred_gen.append(__g)\n",
    "    overall_true_cat.append(y[df_test.index])\n",
    "                         \n",
    "    cat_results.append(score)\n",
    "    gen_cat_results.append(gen_score)             \n",
    "    category.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_specific</th>\n",
       "      <th>generic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>office_products</td>\n",
       "      <td>0.599596</td>\n",
       "      <td>0.617719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toys</td>\n",
       "      <td>0.591861</td>\n",
       "      <td>0.639055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon_fashion</td>\n",
       "      <td>0.527179</td>\n",
       "      <td>0.584936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video_games</td>\n",
       "      <td>0.685761</td>\n",
       "      <td>0.692331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pet_supplies</td>\n",
       "      <td>0.597508</td>\n",
       "      <td>0.626997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all_beauty</td>\n",
       "      <td>0.584817</td>\n",
       "      <td>0.601474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>automotive</td>\n",
       "      <td>0.590505</td>\n",
       "      <td>0.612326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tools</td>\n",
       "      <td>0.607845</td>\n",
       "      <td>0.626624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movies</td>\n",
       "      <td>0.712731</td>\n",
       "      <td>0.693148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>music</td>\n",
       "      <td>0.661414</td>\n",
       "      <td>0.666858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grocery</td>\n",
       "      <td>0.590846</td>\n",
       "      <td>0.603313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kindle</td>\n",
       "      <td>0.516871</td>\n",
       "      <td>0.563855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>software</td>\n",
       "      <td>0.677868</td>\n",
       "      <td>0.688860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>musical_instruments</td>\n",
       "      <td>0.660593</td>\n",
       "      <td>0.661102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>luxury_beauty</td>\n",
       "      <td>0.605751</td>\n",
       "      <td>0.598231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>appliances</td>\n",
       "      <td>0.712780</td>\n",
       "      <td>0.693046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arts_crafts</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>0.708822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>industrial</td>\n",
       "      <td>0.603840</td>\n",
       "      <td>0.628368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>prime_pantry</td>\n",
       "      <td>0.569972</td>\n",
       "      <td>0.593354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patio</td>\n",
       "      <td>0.639369</td>\n",
       "      <td>0.628803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cds_and_vinyl</td>\n",
       "      <td>0.725741</td>\n",
       "      <td>0.732843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category  category_specific   generic\n",
       "0       office_products           0.599596  0.617719\n",
       "1                  toys           0.591861  0.639055\n",
       "2        amazon_fashion           0.527179  0.584936\n",
       "3           video_games           0.685761  0.692331\n",
       "4          pet_supplies           0.597508  0.626997\n",
       "5            all_beauty           0.584817  0.601474\n",
       "6            automotive           0.590505  0.612326\n",
       "7                 tools           0.607845  0.626624\n",
       "8                movies           0.712731  0.693148\n",
       "9                 music           0.661414  0.666858\n",
       "10              grocery           0.590846  0.603313\n",
       "11               kindle           0.516871  0.563855\n",
       "12             software           0.677868  0.688860\n",
       "13  musical_instruments           0.660593  0.661102\n",
       "14        luxury_beauty           0.605751  0.598231\n",
       "15           appliances           0.712780  0.693046\n",
       "16          arts_crafts           0.703600  0.708822\n",
       "17           industrial           0.603840  0.628368\n",
       "18         prime_pantry           0.569972  0.593354\n",
       "19                patio           0.639369  0.628803\n",
       "20        cds_and_vinyl           0.725741  0.732843"
      ]
     },
     "execution_count": 1437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = {'category': category, 'category_specific': cat_results, 'generic': gen_cat_results}\n",
    "category_specific_f1 = pd.DataFrame(d_)\n",
    "category_specific_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    17\n",
       "True      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(category_specific_f1['category_specific'] > category_specific_f1['generic']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our category specific model only outperforms the predictions made by the generic model in 4 categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1438,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_T = []\n",
    "for i in range(0, len(overall_true_cat)): #Concatenating True values of Y\n",
    "    f1_T = f1_T + list(overall_true_cat[i])\n",
    "\n",
    "f1_P_cat = []\n",
    "for i in range(0, len(overall_pred_cat)):\n",
    "    f1_P_cat = f1_P_cat + list(overall_pred_cat[i]) #Concatenating Predicted values from Category Specific Model\n",
    "    \n",
    "f1_P_gen = []\n",
    "for i in range(0, len(overall_pred_gen)):m\n",
    "    f1_P_gen = f1_P_gen + list(overall_pred_gen[i]) #Concatenating Predicted values from Generalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758373425197983"
      ]
     },
     "execution_count": 1436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(f1_T, f1_P_cat, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6684169363483298"
      ]
     },
     "execution_count": 1441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(f1_T, f1_P_gen, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a random forest model that is trained on category specific data outperforms all the other models with an f1 score of 0.676."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting RF F1 scores by discrimination threshold\n",
    "plt.scatter(thresh_list,f1_score_rev_RF)\n",
    "plt.xlabel('Discrimination Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Random Forest F1 Scores by Discrimination Threshold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
